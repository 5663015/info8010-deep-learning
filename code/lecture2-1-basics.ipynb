{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.tensor(1., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.2773, -0.0396,  0.4586],\n",
      "        [ 0.0978, -0.3581, -0.1764]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.3441, 0.4651], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.randn(5, 3)\n",
    "y = torch.randn(5, 2)\n",
    "\n",
    "# Build a linear layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print('w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5113, -0.0705],\n",
      "        [ 0.4701,  0.7327],\n",
      "        [ 0.5102,  0.5950],\n",
      "        [ 0.3280,  0.8065],\n",
      "        [-0.3056,  1.2092]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation.\n",
    "pred = linear(x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.6172, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build Loss and Optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  tensor([[ 0.0381,  0.1562,  0.5579],\n",
      "        [ 0.1110, -0.9731, -0.5821]])\n",
      "dL/db:  tensor([0.6711, 0.9915])\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  1.0265560150146484\n"
     ]
    }
   ],
   "source": [
    "# 1-step Optimization (gradient descent).\n",
    "optimizer.step()\n",
    "\n",
    "# You can also do optimization at the low level as shown below.\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# Print out the loss after optimization.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "b = torch.from_numpy(a)      # convert numpy array to torch tensor\n",
    "c = b.numpy()                # convert torch tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download and construct dataset.\n",
    "train_dataset = dsets.CIFAR10(root='./data/',\n",
    "                              train=True, \n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Select one data pair (read data from disk).\n",
    "image, label = train_dataset[7]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilles/anaconda3/envs/ggi/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F01BD09CC88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import toimage\n",
    "toimage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (this provides queue and thread in a very simple way).\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "# When iteration starts, queue and thread start to load dataset from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Your training code will be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input pipeline for custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should build custom dataset as below.\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file path or list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# Then, you can just use prebuilt torch's data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load pretrained resnet.\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only top layer of the model.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Replace top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51300\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1568e-01,  5.3433e-01,  7.4242e-01,  6.2981e-02,  2.3663e-01,\n",
      "          5.6432e-01, -7.8718e-02, -2.9503e-01,  8.7011e-01, -1.3383e-02,\n",
      "          1.0284e+00, -3.2181e-01, -8.1243e-01,  2.7487e-01, -6.5879e-01,\n",
      "          6.7676e-01,  1.4149e-01,  1.8571e-03,  8.2447e-01, -1.1496e+00,\n",
      "         -6.0994e-01, -6.2465e-01, -2.5588e-01,  6.1770e-01, -4.9594e-01,\n",
      "          3.3104e-01,  3.0861e-01, -9.2243e-01,  4.8901e-01,  8.5883e-02,\n",
      "          1.3050e+00,  4.7985e-02,  4.5465e-01, -2.4142e-02,  6.5557e-01,\n",
      "          2.4600e-01,  2.4094e-01,  3.2962e-01,  4.0465e-01,  5.4254e-01,\n",
      "         -1.0083e+00, -1.2786e+00,  2.4001e-01, -1.2375e+00, -7.5149e-02,\n",
      "          7.6989e-01, -5.8451e-01,  6.0738e-01,  5.6997e-02,  4.1275e-01,\n",
      "          1.2219e-01,  8.6224e-01, -6.8760e-01,  4.8097e-01,  8.9219e-01,\n",
      "          2.8951e-01, -1.2494e+00, -4.4353e-02, -7.0654e-01, -7.4033e-01,\n",
      "          1.9318e-01,  9.2329e-01,  1.1193e+00,  1.0030e-01,  8.9788e-01,\n",
      "         -2.7936e-01, -7.9837e-01,  5.8041e-02,  7.7938e-01,  3.9216e-01,\n",
      "          3.1547e-01,  1.1993e+00, -2.1405e-01, -3.7892e-02, -6.1190e-02,\n",
      "         -5.1715e-01, -4.8566e-01, -1.7890e-01,  1.6909e-01,  8.8059e-01,\n",
      "         -6.4341e-01, -1.2953e+00, -4.1447e-01,  1.2985e+00, -6.4476e-01,\n",
      "         -2.4856e-02,  3.7726e-01, -6.9581e-01, -4.9061e-02, -2.2578e-01,\n",
      "          5.2311e-01, -1.1769e+00,  1.4299e-01, -1.4621e-01,  9.9141e-02,\n",
      "         -1.3059e+00,  1.4633e-01, -6.7527e-01, -1.6055e-01,  1.4403e-01],\n",
      "        [-1.0489e+00, -2.2439e-01,  1.0144e+00, -4.9365e-01,  9.0548e-02,\n",
      "          9.3051e-01, -3.5451e-01, -2.9294e-01,  2.5078e-01, -4.7822e-01,\n",
      "          9.0557e-01, -2.9732e-01, -6.3600e-01,  1.0824e-01, -2.4982e-01,\n",
      "          7.6348e-01,  5.4745e-01, -8.7750e-01,  1.0064e+00, -1.2708e-01,\n",
      "         -3.5021e-01, -6.0141e-01, -2.8131e-01,  5.6986e-01, -1.8795e-01,\n",
      "         -5.9471e-01,  5.1287e-01, -1.0366e+00,  4.2084e-01,  7.4432e-02,\n",
      "          8.5736e-01,  1.6089e-01, -6.1548e-02, -6.1699e-01, -5.2043e-01,\n",
      "          1.1300e-01,  2.3061e-01,  4.3185e-02,  6.7820e-01,  1.2620e+00,\n",
      "         -5.9865e-01, -1.8246e+00,  4.6355e-01, -7.6922e-01, -2.5989e-02,\n",
      "          5.9072e-01, -3.7688e-01,  1.5937e-01,  3.5045e-01,  6.5463e-02,\n",
      "          1.0358e+00,  1.1552e+00, -8.4280e-01,  7.4646e-01,  1.3409e+00,\n",
      "          2.2700e-01, -1.1343e+00,  2.8120e-02, -1.3058e+00, -5.2462e-01,\n",
      "          6.1982e-01,  9.3838e-01,  6.8139e-01,  2.7527e-02,  7.4837e-01,\n",
      "         -3.3701e-01, -8.5047e-01,  2.8376e-01,  2.4048e-01,  8.5482e-01,\n",
      "          5.5994e-01,  7.0035e-02,  1.5693e-02,  1.4181e-01, -9.1087e-02,\n",
      "         -9.9194e-01, -9.8849e-01, -2.8009e-01, -3.3669e-01, -1.7300e-01,\n",
      "         -1.4502e-01, -1.1160e+00,  3.4969e-01,  8.2387e-01, -1.4307e-01,\n",
      "         -1.0392e+00,  5.0409e-01, -1.4998e+00, -9.3970e-01,  3.8055e-01,\n",
      "         -1.3994e-01, -9.0702e-02, -3.8984e-02,  2.8332e-01, -6.0786e-01,\n",
      "         -1.0826e+00,  1.9197e-02, -8.3331e-01, -2.3051e-01, -2.8973e-01],\n",
      "        [-1.4672e+00, -4.9083e-01,  1.3063e+00, -3.6872e-01,  2.0403e-01,\n",
      "          6.2332e-01,  4.5922e-02, -1.1238e+00,  2.3252e-01,  7.8592e-02,\n",
      "          5.7296e-01, -1.3946e-01, -4.0841e-01,  9.9974e-03, -3.2127e-01,\n",
      "          9.5300e-01,  1.0393e+00, -3.5687e-01,  3.8662e-01, -7.7018e-01,\n",
      "         -2.1501e-01, -5.1927e-01,  1.0090e-01,  2.6136e-01, -5.1557e-01,\n",
      "         -1.8249e-01,  5.9750e-01, -1.0368e+00,  2.9556e-01,  1.5723e-01,\n",
      "          1.1822e+00, -2.8599e-01, -4.4920e-01, -3.5101e-01,  4.4614e-01,\n",
      "         -4.4284e-01, -7.6471e-02, -3.5707e-01,  3.2296e-01,  9.9970e-01,\n",
      "         -5.9062e-01, -1.1945e+00,  2.4142e-01, -9.0558e-01,  1.9588e-01,\n",
      "          3.9647e-01, -7.0634e-01,  8.3353e-01,  4.4616e-02, -1.6171e-01,\n",
      "          4.6959e-01,  4.8843e-01, -1.1202e+00,  6.8622e-01,  1.4616e+00,\n",
      "          6.3993e-01, -1.5828e+00,  2.9290e-01, -2.9090e-01, -6.8919e-01,\n",
      "          4.3840e-01,  2.9988e-01,  8.9544e-01, -9.7835e-02,  1.5664e-01,\n",
      "         -3.2823e-01, -3.6684e-01,  2.1786e-02,  5.7863e-01, -5.2657e-02,\n",
      "          8.5973e-01, -1.8046e-01,  1.6117e-01,  2.1733e-01, -4.7611e-01,\n",
      "         -5.2486e-01, -1.2452e+00,  1.4676e-01, -3.2064e-01, -3.0046e-01,\n",
      "         -1.6826e-01, -9.8523e-01, -1.4799e-01,  2.1932e-01, -5.4908e-02,\n",
      "         -7.7998e-01,  4.3516e-01, -8.2807e-01, -4.0841e-01,  4.1574e-01,\n",
      "          6.5307e-01, -2.4425e-01, -2.3553e-01, -5.0695e-01, -1.2297e+00,\n",
      "         -1.5410e+00, -4.5836e-01, -4.9247e-01,  1.1322e-01,  2.0360e-01],\n",
      "        [-6.4451e-01, -1.8445e-01,  6.5034e-01, -5.0905e-01,  5.8996e-01,\n",
      "          5.1346e-01,  1.2005e-01, -9.7625e-01,  5.6491e-01, -4.4332e-01,\n",
      "          4.8095e-01, -1.5774e-01, -2.4742e-01, -1.1177e-01, -2.6704e-01,\n",
      "          1.0819e+00,  7.3495e-01,  1.6399e-01,  5.0561e-01, -8.0113e-01,\n",
      "         -1.1055e+00, -4.7858e-01, -8.6682e-02,  4.3693e-01, -3.9595e-01,\n",
      "         -3.4488e-01,  6.1094e-01, -8.3288e-01,  2.9077e-01, -4.7481e-01,\n",
      "          3.8912e-01,  1.6630e-01, -2.8022e-01, -5.7430e-01,  6.0157e-01,\n",
      "         -5.8284e-02, -5.1866e-01,  1.6457e-01,  3.8893e-01,  9.0421e-01,\n",
      "         -3.5022e-01, -6.7936e-01, -2.1703e-01, -9.3791e-01, -1.5112e-02,\n",
      "          3.9534e-01, -1.1128e+00, -1.3600e-01, -3.6052e-02, -4.6156e-01,\n",
      "         -5.8509e-04, -9.3546e-02, -1.0676e+00,  1.0957e+00,  1.8424e-01,\n",
      "          4.4465e-02, -8.0184e-01,  4.1480e-01, -4.7628e-01, -4.5511e-01,\n",
      "          2.5973e-01,  6.0293e-01,  9.6357e-01, -3.0614e-01,  4.8277e-01,\n",
      "         -8.2894e-01, -7.3210e-01,  1.9380e-01,  8.7137e-01,  2.3958e-01,\n",
      "          4.1303e-01,  8.4058e-02, -6.3840e-02, -7.2316e-02, -4.9870e-01,\n",
      "         -5.0747e-01, -6.3689e-01,  2.3258e-01, -1.3876e-01,  1.9708e-01,\n",
      "         -2.6535e-01, -6.7286e-01,  2.5265e-01,  6.0225e-01, -2.2417e-01,\n",
      "         -2.6444e-01,  5.6517e-01, -1.0535e+00, -1.0273e+00, -1.9993e-01,\n",
      "          5.0690e-01, -4.2064e-01,  2.9153e-01,  3.1141e-01, -2.4538e-02,\n",
      "         -1.7582e+00, -9.1958e-02, -5.3037e-01,  2.2750e-01, -1.1732e-01],\n",
      "        [-2.3546e-01,  4.5648e-01,  1.6899e+00,  2.7790e-01,  1.5476e-02,\n",
      "          7.8928e-01,  5.7744e-01, -1.0565e+00,  4.4951e-01,  2.4888e-01,\n",
      "          6.3051e-01, -4.2219e-01, -3.5579e-01, -2.2441e-02, -7.3549e-01,\n",
      "          1.0077e+00,  1.0978e+00, -5.3822e-01,  2.3533e-01, -1.0756e+00,\n",
      "         -7.6652e-01, -5.1782e-01, -4.4545e-01,  1.4502e-01, -1.7172e-01,\n",
      "          4.1444e-01,  9.7951e-01, -4.0242e-01,  3.1430e-01, -6.2543e-01,\n",
      "          2.0948e-01, -2.1692e-01,  6.1826e-02, -2.6053e-01,  9.7293e-01,\n",
      "          1.5776e-02, -2.8826e-01,  1.0016e-01,  2.5311e-01,  4.3699e-01,\n",
      "         -7.9465e-01, -1.2962e+00,  5.3798e-01, -9.2731e-01,  8.1883e-01,\n",
      "          7.2608e-01, -1.7149e+00,  8.7831e-01,  1.6702e-01,  5.4304e-01,\n",
      "         -1.6795e-01,  5.8703e-01, -6.1987e-01,  2.4504e-01,  1.2499e+00,\n",
      "          2.4382e-01, -1.7677e+00,  4.0025e-01, -1.1347e+00, -1.0659e+00,\n",
      "          3.2025e-01,  7.3261e-01,  5.5148e-01, -4.7675e-01,  5.1052e-01,\n",
      "          5.9182e-01, -8.7252e-01, -1.2652e-01,  2.8753e-01, -2.6181e-01,\n",
      "          3.2903e-01,  2.5268e-01, -5.7240e-02,  2.0730e-02, -1.0358e-01,\n",
      "         -4.3822e-01, -5.8800e-01, -1.6022e-01, -5.3996e-02,  3.7958e-01,\n",
      "         -3.7476e-01, -5.9317e-01, -2.5666e-02, -2.2237e-01, -1.4248e-01,\n",
      "         -1.1131e+00,  3.5072e-01, -9.5667e-01, -4.2666e-01, -3.3334e-01,\n",
      "          6.1853e-01, -7.8506e-01, -4.0480e-01,  1.0632e-01,  1.2754e-01,\n",
      "         -1.5894e+00, -3.8948e-01, -3.6661e-01, -3.7545e-01,  2.7191e-01],\n",
      "        [-8.5526e-01,  1.4108e-01,  9.9391e-01,  6.3411e-02,  5.8578e-01,\n",
      "          3.4784e-01,  5.3299e-01, -9.3432e-01,  4.5394e-01,  7.8689e-02,\n",
      "          6.0218e-01, -7.8595e-01, -5.1891e-01, -7.2918e-02, -1.4427e-01,\n",
      "          1.3435e+00,  6.9436e-01, -3.4515e-01,  8.3809e-01, -1.2417e+00,\n",
      "         -6.4793e-01, -5.2925e-01, -4.5119e-01,  2.3088e-01, -7.2059e-01,\n",
      "         -1.2801e-01,  7.4327e-01, -2.4916e-02, -5.1913e-02, -4.2552e-01,\n",
      "          5.0697e-01, -2.8573e-01,  2.1618e-01,  6.6947e-01,  2.4537e-01,\n",
      "         -1.9007e-02,  5.6119e-01,  5.8489e-01,  1.4112e-01,  6.6232e-01,\n",
      "         -2.9263e-01, -9.6940e-01,  4.4078e-01, -7.2479e-01,  4.0309e-01,\n",
      "          5.9789e-01, -2.9119e-01, -1.5609e-01,  1.3655e-01,  5.5193e-02,\n",
      "          1.7077e-01,  1.3165e+00, -1.1859e+00,  9.2066e-01,  1.4459e+00,\n",
      "          1.6710e-01, -1.8093e+00, -1.7311e-01, -1.6358e+00, -8.7167e-01,\n",
      "          6.5007e-01,  7.6554e-01,  5.7949e-01, -5.1973e-01,  1.2468e+00,\n",
      "         -1.5811e-01, -1.1072e+00,  5.3132e-01,  1.8752e-01,  1.7679e-02,\n",
      "          8.7979e-01, -2.4327e-01, -2.1602e-02,  3.4782e-02, -1.3512e-01,\n",
      "         -5.9517e-01, -8.0513e-01, -5.5045e-01,  4.1588e-01,  1.2555e-01,\n",
      "         -2.4643e-01, -7.1100e-01, -4.5615e-01,  5.1646e-01, -9.0628e-02,\n",
      "         -9.6815e-01,  6.4873e-01, -1.1887e+00, -6.4795e-01,  5.3227e-02,\n",
      "          6.4980e-01, -4.0232e-03, -6.8316e-02,  2.0353e-01,  1.0083e-01,\n",
      "         -1.9969e+00, -1.8974e-01, -5.4151e-01,  1.5467e-01,  4.2538e-01],\n",
      "        [-9.9545e-02,  4.5263e-01,  1.1628e+00, -4.2754e-01,  5.6633e-02,\n",
      "          4.8227e-01,  3.5882e-01, -4.4328e-01,  6.1842e-01, -5.1646e-01,\n",
      "          5.5578e-01, -7.4881e-01, -4.1533e-01, -2.6248e-01, -4.6823e-01,\n",
      "          6.6652e-01,  3.7851e-01, -2.1162e-01,  6.0944e-01, -4.3862e-01,\n",
      "         -3.4551e-01, -1.3726e+00,  4.2058e-01,  6.0231e-01,  5.4456e-02,\n",
      "         -7.1148e-01,  1.2790e-01, -2.3259e-01,  5.8201e-01, -3.2509e-01,\n",
      "          4.8682e-01,  4.3056e-01,  6.2238e-01, -5.3908e-01, -5.6620e-01,\n",
      "         -7.2449e-01, -2.5094e-01, -9.9667e-02,  8.8103e-01,  6.4577e-01,\n",
      "         -4.9561e-01, -1.6622e+00,  6.8411e-01, -5.7723e-01,  2.2493e-02,\n",
      "          2.2634e-01, -5.0262e-01,  3.8786e-01,  1.1576e-01,  2.0119e-01,\n",
      "         -1.3612e-01,  5.9766e-01, -1.5392e+00,  4.9799e-01,  8.7696e-01,\n",
      "          3.3691e-01, -1.3136e+00, -2.7544e-01, -4.0924e-01, -1.1134e+00,\n",
      "          1.0688e-01,  2.0985e-01,  4.9370e-01, -3.7965e-02,  1.0888e+00,\n",
      "          4.3783e-02, -8.4352e-01, -5.7056e-01,  5.4400e-01, -5.2506e-02,\n",
      "          2.9647e-01, -6.2424e-02, -1.1674e-01, -5.3126e-01, -3.3586e-01,\n",
      "         -2.5588e-01, -1.1849e+00, -2.5057e-01, -3.9089e-01,  4.1912e-01,\n",
      "         -6.1865e-01, -8.8929e-01,  2.3654e-01,  2.2391e-01,  1.7626e-01,\n",
      "         -7.5338e-01,  4.7654e-01, -1.2263e+00, -1.5360e+00,  6.8648e-02,\n",
      "          1.3345e-01,  3.0912e-02, -4.2176e-02,  2.3945e-02,  4.5037e-01,\n",
      "         -1.0079e+00, -4.7745e-01, -6.7160e-02,  9.4312e-02,  3.6409e-01],\n",
      "        [-4.6305e-01,  5.1834e-01,  1.6838e+00, -7.2336e-02,  6.5938e-01,\n",
      "          1.1262e-01,  4.3508e-01, -2.8821e-01,  7.6125e-01,  3.7366e-01,\n",
      "          3.7350e-01, -9.9572e-01, -9.9722e-02, -3.8729e-01, -6.1757e-01,\n",
      "          1.3646e+00,  9.6551e-01, -2.6894e-01,  9.7530e-02, -1.8294e+00,\n",
      "         -1.0273e+00, -1.0801e+00,  2.7748e-01,  5.8044e-01, -1.7904e-01,\n",
      "         -2.4353e-01,  5.1757e-01, -3.8856e-01,  6.6183e-01, -3.7381e-01,\n",
      "          6.6223e-02, -1.8557e-01, -2.3779e-01, -8.2561e-01,  3.1306e-01,\n",
      "         -9.3002e-02, -7.5024e-02, -4.8989e-01,  4.0200e-01,  4.9699e-01,\n",
      "         -1.2957e+00, -1.6100e+00, -4.0145e-01, -4.8512e-01,  4.6145e-01,\n",
      "          4.4910e-01, -7.5181e-01,  4.4552e-01,  8.7010e-02, -4.8235e-01,\n",
      "         -2.5038e-01,  6.1620e-01, -7.2638e-01,  2.8642e-01,  7.6473e-01,\n",
      "          3.8739e-01, -1.6888e+00, -2.1233e-01, -7.9243e-01, -9.6202e-01,\n",
      "          2.4048e-01,  3.7054e-01,  7.4957e-01, -1.1306e-01,  1.1984e+00,\n",
      "          1.6099e-01, -7.4809e-01, -2.6753e-01,  7.3669e-01,  1.6703e-01,\n",
      "          4.5203e-01,  4.1828e-01,  4.0809e-02, -4.8996e-01,  4.9897e-01,\n",
      "         -1.9355e-01, -8.7946e-01, -2.7761e-01, -6.3353e-01,  2.4640e-01,\n",
      "         -2.8155e-01, -9.0355e-01, -2.7168e-01,  6.0577e-01,  1.7249e-01,\n",
      "         -4.0889e-01,  4.4019e-01, -1.6272e+00, -2.0195e-01, -1.0440e-01,\n",
      "          5.2217e-01, -6.1146e-01,  3.9862e-01,  1.9535e-01, -9.9107e-02,\n",
      "         -1.2418e+00, -9.9180e-02, -6.6450e-01,  1.1691e-01,  4.4677e-01],\n",
      "        [-8.9433e-01, -9.4286e-01,  1.7406e+00, -2.2715e-01,  4.0002e-01,\n",
      "         -1.6678e-01,  1.3469e-01, -5.1433e-01,  8.3105e-01, -1.7629e-01,\n",
      "          6.4770e-01, -2.5292e-01, -6.4582e-01, -1.9146e-01, -2.5379e-01,\n",
      "          9.4049e-01,  8.2129e-01, -9.3017e-02,  2.6397e-01, -7.0293e-01,\n",
      "         -4.3462e-01, -1.0184e+00, -3.7164e-01,  2.6606e-01, -1.5976e-01,\n",
      "         -4.4403e-01,  1.7888e-01, -2.6115e-01,  4.7297e-01, -5.9279e-01,\n",
      "          6.2821e-01,  3.8185e-02, -3.0483e-01, -5.6153e-01,  1.3023e-01,\n",
      "         -2.1024e-01, -5.1673e-01, -5.1956e-01,  2.0559e-01,  1.1110e+00,\n",
      "         -2.2326e-01, -1.2754e+00, -5.0106e-01, -1.2646e+00,  4.3092e-01,\n",
      "          1.3265e-01, -8.4861e-01,  3.3171e-01, -3.5452e-01, -2.1138e-01,\n",
      "          4.0231e-01,  4.3026e-02, -6.1505e-01,  2.9933e-01,  9.9080e-01,\n",
      "          3.5775e-04, -1.2113e+00,  3.0499e-01, -2.2328e-01, -7.8426e-02,\n",
      "          2.4373e-02,  2.9954e-01,  1.0855e+00, -3.5352e-01,  7.6107e-01,\n",
      "         -2.7074e-01, -7.0973e-01,  2.5820e-01,  6.0487e-01,  3.4473e-01,\n",
      "          5.4503e-01, -3.5874e-01, -1.2293e-01,  5.7117e-02, -3.2775e-02,\n",
      "         -7.1116e-01, -5.6336e-01,  1.4863e-01, -2.2671e-01,  1.0826e-01,\n",
      "          1.1524e-01, -1.4912e-01, -4.9783e-01,  8.9485e-01,  1.2777e-01,\n",
      "         -1.0374e+00,  2.6380e-01, -1.6005e+00, -6.0141e-01,  8.0707e-02,\n",
      "          6.5542e-01, -1.8492e-01,  5.4372e-01,  4.0704e-01, -2.1581e-01,\n",
      "         -1.1203e+00,  5.2757e-02, -4.5945e-01, -1.0222e-01, -4.9956e-01],\n",
      "        [-2.5360e-01,  2.7487e-01,  1.2625e+00, -2.8478e-01,  7.4940e-01,\n",
      "          8.3104e-01,  2.2043e-02, -5.6938e-01,  4.1686e-01, -4.5741e-02,\n",
      "          5.9065e-01, -2.9638e-01, -9.2732e-01, -1.2067e-01,  1.2335e-01,\n",
      "          6.9599e-01,  8.5408e-01,  1.8938e-01,  5.5703e-01, -5.9906e-01,\n",
      "         -1.2537e+00, -3.6391e-01, -5.3316e-01,  7.5125e-01, -1.5626e-01,\n",
      "         -6.1024e-01,  1.1069e-01, -8.6748e-02, -5.8553e-01, -7.4129e-01,\n",
      "          2.0086e-01,  1.9146e-01, -6.3855e-01, -2.8575e-01,  5.7429e-01,\n",
      "          2.3438e-01,  3.7326e-01,  1.8362e-01,  9.7941e-01,  1.2884e+00,\n",
      "         -6.7469e-01, -3.4190e-01, -6.9264e-01, -6.2492e-01,  7.6822e-01,\n",
      "          3.3266e-01,  5.3784e-02,  1.2602e-01, -1.5137e-01, -2.8803e-01,\n",
      "          1.3166e-01,  7.0918e-02, -1.0707e+00,  1.0106e+00,  1.0289e+00,\n",
      "          2.8888e-01, -6.7497e-01,  7.2629e-02, -3.1760e-01,  8.2983e-02,\n",
      "          4.5134e-01,  7.2526e-01,  6.0427e-01, -5.8200e-01,  1.1134e+00,\n",
      "         -3.7048e-01, -6.3696e-01,  3.1353e-01,  3.5057e-01,  4.0644e-01,\n",
      "          3.4244e-01,  1.2146e-01,  1.2127e-01, -4.0047e-01, -2.6629e-01,\n",
      "         -1.0224e+00, -9.5685e-01, -5.0827e-01,  7.4550e-01,  1.1653e+00,\n",
      "          1.3362e-01, -7.9008e-01, -1.0183e+00,  4.9130e-01, -4.4437e-02,\n",
      "         -1.0020e+00,  2.3739e-01, -1.4460e+00, -5.8672e-01,  2.2967e-01,\n",
      "          5.9839e-01,  3.0090e-01, -2.0404e-01, -5.2310e-01, -1.0586e-02,\n",
      "         -1.7498e+00,  3.5503e-01, -1.1427e+00,  2.3771e-01,  5.1551e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# For test.\n",
    "images = torch.randn(10, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print(outputs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.pkl')\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "# Save and load only the model parameters(recommended).\n",
    "torch.save(resnet.state_dict(), 'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
