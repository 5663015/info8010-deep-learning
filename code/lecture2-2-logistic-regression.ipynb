{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "X, y = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01e6bc2e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0632, -0.0498,  0.0794,  0.0055, -0.0225, -0.0461,  0.2332, -0.1760,\n",
       "         -0.2162, -0.1668],\n",
       "        [-0.0433,  0.0111,  0.0076,  0.0776, -0.0804,  0.0187,  0.1166, -0.3213,\n",
       "         -0.1408, -0.0492],\n",
       "        [-0.1218,  0.1563,  0.1808, -0.0773, -0.0679, -0.1908, -0.1435, -0.1074,\n",
       "         -0.0493,  0.3906],\n",
       "        [-0.0064,  0.0788,  0.0192, -0.1097,  0.1543, -0.1648, -0.1651, -0.1731,\n",
       "          0.0897,  0.1604],\n",
       "        [ 0.0468,  0.3024,  0.1300, -0.2080,  0.1456,  0.1087, -0.0081,  0.2187,\n",
       "          0.1317,  0.1757],\n",
       "        [-0.0341,  0.1822,  0.2308, -0.0318,  0.0303, -0.0546, -0.1794, -0.0785,\n",
       "          0.2415,  0.2383],\n",
       "        [-0.0764,  0.0414, -0.0463, -0.3282, -0.0428,  0.0028,  0.0865, -0.1913,\n",
       "         -0.1009,  0.0364],\n",
       "        [ 0.2203,  0.0893,  0.0305, -0.0840, -0.0126,  0.0689,  0.0640, -0.0959,\n",
       "         -0.2130,  0.0122],\n",
       "        [ 0.1717,  0.3325,  0.3922, -0.0238,  0.1317,  0.1874,  0.1751, -0.0215,\n",
       "          0.1493,  0.0107],\n",
       "        [ 0.0359, -0.0957,  0.0394, -0.1670, -0.0470,  0.1449,  0.0098, -0.1720,\n",
       "         -0.2057, -0.0353],\n",
       "        [ 0.1657, -0.2070,  0.2391,  0.0891,  0.3102,  0.0749,  0.1974, -0.0967,\n",
       "         -0.0941,  0.0021],\n",
       "        [ 0.1256,  0.0283, -0.0745, -0.0617,  0.1114,  0.2047,  0.0050,  0.0412,\n",
       "          0.0575, -0.2199],\n",
       "        [-0.0159,  0.1153,  0.3136, -0.1551,  0.4217,  0.2402,  0.2334, -0.1075,\n",
       "          0.1497,  0.2034],\n",
       "        [ 0.0836,  0.2584, -0.0035, -0.1971,  0.0794,  0.1263,  0.0064,  0.0449,\n",
       "          0.1884,  0.0266],\n",
       "        [-0.0227,  0.0162,  0.0173, -0.1736, -0.0087, -0.0227,  0.0838,  0.0687,\n",
       "          0.0396, -0.0131],\n",
       "        [ 0.0982, -0.0625,  0.1272, -0.1148, -0.1001,  0.1774,  0.0762, -0.0670,\n",
       "         -0.1680, -0.0227],\n",
       "        [ 0.0828, -0.1683, -0.0041, -0.2401,  0.0083,  0.1272,  0.2672, -0.4141,\n",
       "          0.1036, -0.0663],\n",
       "        [ 0.1093, -0.0327,  0.1647, -0.1880,  0.1372,  0.1541,  0.3944, -0.1202,\n",
       "          0.2416,  0.0383],\n",
       "        [-0.0979, -0.0670, -0.0408, -0.0747,  0.0226, -0.0358,  0.0135,  0.1836,\n",
       "         -0.2922,  0.0712],\n",
       "        [ 0.1400,  0.1948,  0.0231,  0.0292,  0.0760, -0.0538,  0.0278, -0.1331,\n",
       "         -0.1865,  0.0175],\n",
       "        [-0.1298,  0.0067,  0.2987, -0.0084,  0.3021,  0.1262,  0.2295, -0.4890,\n",
       "          0.0829, -0.0875],\n",
       "        [ 0.1329, -0.0276,  0.1274,  0.0795,  0.1811,  0.1637,  0.1617,  0.0702,\n",
       "          0.0751, -0.0678],\n",
       "        [-0.0461,  0.2506,  0.1342, -0.0747,  0.3351,  0.0938, -0.0318, -0.2772,\n",
       "          0.0712,  0.0924],\n",
       "        [ 0.1078,  0.0519,  0.4288, -0.0816,  0.0427,  0.1601, -0.0173,  0.0972,\n",
       "          0.0931,  0.5400],\n",
       "        [ 0.2419,  0.0565,  0.3089, -0.1835,  0.0026,  0.3034, -0.0468, -0.0579,\n",
       "          0.1446, -0.0096],\n",
       "        [ 0.0975,  0.1538,  0.0969, -0.1568,  0.0152,  0.1864,  0.0355, -0.1037,\n",
       "          0.0922, -0.1861],\n",
       "        [ 0.0209,  0.3038, -0.0245,  0.1156,  0.0085, -0.1838,  0.1807, -0.0453,\n",
       "         -0.2385,  0.0622],\n",
       "        [-0.1578,  0.1587,  0.4352, -0.1562,  0.3746,  0.1060,  0.2261, -0.3449,\n",
       "         -0.0274,  0.1137],\n",
       "        [ 0.1517,  0.3067,  0.1549, -0.0972,  0.1607,  0.1491,  0.1582,  0.0108,\n",
       "          0.1087, -0.0936],\n",
       "        [ 0.1141, -0.0672,  0.1282, -0.1602, -0.1424,  0.1262,  0.0828, -0.1614,\n",
       "         -0.1765,  0.0191],\n",
       "        [ 0.2449,  0.0998,  0.2647, -0.0473,  0.1506,  0.0382,  0.1561, -0.1542,\n",
       "          0.0534,  0.1347],\n",
       "        [-0.0236,  0.1972,  0.1260,  0.0258,  0.0948, -0.0470,  0.0873,  0.1357,\n",
       "         -0.0161, -0.0418],\n",
       "        [ 0.1428,  0.2424, -0.1003, -0.2067, -0.0513, -0.0958, -0.1876, -0.1689,\n",
       "          0.1536,  0.0800],\n",
       "        [ 0.1597,  0.1917,  0.1249, -0.0105,  0.0225,  0.2015,  0.1381, -0.0593,\n",
       "          0.2214, -0.0448],\n",
       "        [-0.0211,  0.0617,  0.1125, -0.1144,  0.1308,  0.0061,  0.2245, -0.1351,\n",
       "          0.1905, -0.0327],\n",
       "        [ 0.0265,  0.2693,  0.1517, -0.1936,  0.1643,  0.0035,  0.1382, -0.1390,\n",
       "          0.1041, -0.0071],\n",
       "        [ 0.1287,  0.1940,  0.2015, -0.1697,  0.0297, -0.0178, -0.0303, -0.2417,\n",
       "          0.0282, -0.1387],\n",
       "        [ 0.0131,  0.1809,  0.0588,  0.0689,  0.0154,  0.1737, -0.0571,  0.0297,\n",
       "          0.0313, -0.0803],\n",
       "        [-0.1091,  0.0067,  0.0384, -0.1394, -0.3278,  0.0025, -0.0109, -0.1963,\n",
       "         -0.1312, -0.1010],\n",
       "        [-0.0427,  0.2010, -0.1279, -0.0498, -0.0909, -0.2299,  0.0797, -0.0825,\n",
       "         -0.0224, -0.2129],\n",
       "        [ 0.1600, -0.1882,  0.4781, -0.1364,  0.0650, -0.0127,  0.1796, -0.2746,\n",
       "          0.0363, -0.0253],\n",
       "        [ 0.0473, -0.0078,  0.1786, -0.2036,  0.0316,  0.0325,  0.2009, -0.1245,\n",
       "         -0.0650,  0.0727],\n",
       "        [-0.1501,  0.0065,  0.1008, -0.2558,  0.1540, -0.0489,  0.1688, -0.2829,\n",
       "          0.1338,  0.4101],\n",
       "        [ 0.2217,  0.1219,  0.3105, -0.0213,  0.3218,  0.2695,  0.4838, -0.2505,\n",
       "          0.2274, -0.3429],\n",
       "        [-0.2911,  0.1272,  0.0280, -0.0747,  0.2125,  0.0437,  0.1054, -0.4187,\n",
       "          0.0430,  0.1318],\n",
       "        [-0.0488, -0.0707,  0.1165, -0.1896,  0.0365, -0.1758, -0.0135, -0.2368,\n",
       "         -0.0454, -0.1470],\n",
       "        [ 0.0810,  0.1716,  0.2228, -0.0806,  0.1773,  0.0672,  0.3202,  0.1569,\n",
       "          0.2425, -0.0609],\n",
       "        [ 0.0057,  0.1463,  0.0996, -0.0944, -0.0230, -0.0425,  0.3288, -0.0936,\n",
       "         -0.1054, -0.1232],\n",
       "        [ 0.0011, -0.0958,  0.2264, -0.0323, -0.1228, -0.0748, -0.0532, -0.3475,\n",
       "         -0.2057, -0.2287],\n",
       "        [ 0.0811, -0.0419,  0.4291, -0.0846,  0.1884,  0.1846,  0.5224, -0.1511,\n",
       "         -0.0396,  0.0374],\n",
       "        [-0.0030,  0.0323,  0.0487,  0.0395, -0.1058, -0.0599,  0.0580,  0.0341,\n",
       "         -0.2783, -0.0377],\n",
       "        [ 0.2477,  0.2316,  0.0309,  0.0462,  0.0670,  0.0484, -0.0116,  0.0839,\n",
       "         -0.0673, -0.1319],\n",
       "        [-0.0511,  0.0267,  0.2805, -0.3704,  0.1611,  0.0344,  0.2069, -0.1191,\n",
       "          0.0940,  0.0218],\n",
       "        [ 0.0732,  0.0950,  0.0382, -0.0492,  0.0891,  0.0547, -0.1389, -0.0204,\n",
       "         -0.0624,  0.0832],\n",
       "        [-0.0105, -0.1488,  0.4716, -0.0103,  0.1062,  0.3894,  0.3671, -0.5519,\n",
       "          0.1681, -0.0315],\n",
       "        [ 0.0616,  0.0263,  0.1984,  0.0676, -0.0437, -0.2586, -0.0066, -0.2501,\n",
       "         -0.2334, -0.0101],\n",
       "        [ 0.0312,  0.2195,  0.0354, -0.2167,  0.1246,  0.1076, -0.0093,  0.1813,\n",
       "          0.2692,  0.0284],\n",
       "        [-0.1219,  0.3177,  0.1762, -0.3173,  0.0298,  0.0399,  0.1931, -0.1024,\n",
       "         -0.0437, -0.0252],\n",
       "        [-0.0151, -0.1666,  0.0301, -0.2181, -0.1921,  0.0557,  0.1918, -0.2073,\n",
       "         -0.1220, -0.0234],\n",
       "        [-0.2788, -0.0582,  0.0578, -0.3314, -0.2223, -0.0911,  0.2107, -0.1325,\n",
       "         -0.1997, -0.0088],\n",
       "        [ 0.0513,  0.0939, -0.0092,  0.1024,  0.0355,  0.0517,  0.2959, -0.2866,\n",
       "          0.1324, -0.1475],\n",
       "        [ 0.1319, -0.0209,  0.0973, -0.0848,  0.1987, -0.0030,  0.0301, -0.2216,\n",
       "         -0.1737, -0.0297],\n",
       "        [-0.0535, -0.0026, -0.0240, -0.1277, -0.0759, -0.2650,  0.1157, -0.3541,\n",
       "          0.0112, -0.1683],\n",
       "        [-0.0081, -0.0525,  0.3079, -0.1966,  0.2246,  0.5285,  0.5056, -0.1272,\n",
       "          0.1120, -0.1103],\n",
       "        [-0.0949,  0.2091,  0.2322, -0.3844,  0.0605,  0.2285,  0.3572, -0.0612,\n",
       "          0.0126, -0.0015],\n",
       "        [-0.0146, -0.0850, -0.0057, -0.1141, -0.0491, -0.0980,  0.1443, -0.2228,\n",
       "         -0.0888, -0.0860],\n",
       "        [-0.0448,  0.1163,  0.3557,  0.1989,  0.0515,  0.0655,  0.1457,  0.0705,\n",
       "          0.0722, -0.0268],\n",
       "        [ 0.0976, -0.0421,  0.1354, -0.1239, -0.0740,  0.1009,  0.0252, -0.0862,\n",
       "         -0.1975,  0.0148],\n",
       "        [-0.1196, -0.0950,  0.1122,  0.1892, -0.0872,  0.1426,  0.1064, -0.1486,\n",
       "         -0.0147, -0.2666],\n",
       "        [ 0.0863, -0.0386, -0.0236, -0.0579, -0.0491, -0.1061, -0.0298, -0.2122,\n",
       "          0.0370,  0.0157],\n",
       "        [ 0.1075,  0.0531,  0.1325, -0.1490,  0.2003,  0.0864,  0.0074,  0.0730,\n",
       "         -0.0160,  0.0769],\n",
       "        [ 0.0068,  0.2989,  0.1258, -0.1556,  0.3167, -0.0050,  0.0972, -0.2474,\n",
       "         -0.0900,  0.1761],\n",
       "        [ 0.0141,  0.2544,  0.2413,  0.0875,  0.1430,  0.3403, -0.0017,  0.0210,\n",
       "          0.2448, -0.2340],\n",
       "        [ 0.0503,  0.1506,  0.1372,  0.0198,  0.3548, -0.0093,  0.5121, -0.3830,\n",
       "          0.0059, -0.5074],\n",
       "        [ 0.0067,  0.0546,  0.0883, -0.1314,  0.1541, -0.1329,  0.2066, -0.0273,\n",
       "          0.1304,  0.0467],\n",
       "        [-0.0633,  0.0845,  0.1881,  0.1544,  0.2317, -0.0492,  0.2512, -0.1964,\n",
       "         -0.0761, -0.3833],\n",
       "        [ 0.4476,  0.1618,  0.2472,  0.3407,  0.0856, -0.0379,  0.0471, -0.0085,\n",
       "          0.1618, -0.1247],\n",
       "        [-0.0208,  0.1520,  0.3202, -0.1096,  0.4791,  0.0208,  0.0765, -0.0941,\n",
       "          0.0407,  0.2673],\n",
       "        [-0.2551,  0.2124,  0.3004,  0.1334,  0.0446,  0.0803,  0.2559, -0.1231,\n",
       "          0.0084,  0.1447],\n",
       "        [-0.0958,  0.1333,  0.3745, -0.0679,  0.4905,  0.1084,  0.1443, -0.1009,\n",
       "         -0.0461,  0.1685],\n",
       "        [-0.3849,  0.2779,  0.3294, -0.0460,  0.1995,  0.2172,  0.2431, -0.2344,\n",
       "          0.3256,  0.2635],\n",
       "        [ 0.0639,  0.1478, -0.0383,  0.0201,  0.2635,  0.0719,  0.2229, -0.3203,\n",
       "          0.0212, -0.0616],\n",
       "        [ 0.0469,  0.3194, -0.0383, -0.1632,  0.1775, -0.0152,  0.0739, -0.2039,\n",
       "         -0.0320, -0.0745],\n",
       "        [-0.1304,  0.0241,  0.1236, -0.2698,  0.1360,  0.3497,  0.1794, -0.2866,\n",
       "         -0.2097, -0.1356],\n",
       "        [ 0.0515,  0.2209,  0.1553, -0.1070,  0.2000,  0.0127, -0.0774,  0.1750,\n",
       "          0.0013,  0.1372],\n",
       "        [ 0.1535,  0.2961,  0.3012, -0.3764,  0.0399,  0.1858,  0.3777, -0.0655,\n",
       "          0.0732,  0.0835],\n",
       "        [ 0.0998, -0.1581,  0.1004,  0.0050,  0.0708,  0.2501,  0.2195, -0.2068,\n",
       "          0.0482, -0.3691],\n",
       "        [ 0.0174,  0.1874,  0.0361, -0.0564,  0.1856,  0.1132,  0.1501, -0.1388,\n",
       "          0.2145,  0.0007],\n",
       "        [ 0.0263,  0.2058,  0.0372, -0.0597, -0.0579, -0.0168,  0.1769, -0.0434,\n",
       "          0.0284, -0.0366],\n",
       "        [ 0.1381,  0.0163,  0.0073, -0.1182, -0.0066, -0.0214,  0.0286, -0.2001,\n",
       "         -0.0910, -0.2651],\n",
       "        [-0.0749, -0.1413,  0.1795, -0.0388,  0.0954, -0.0304,  0.0168, -0.3036,\n",
       "          0.1872, -0.0655],\n",
       "        [-0.1205, -0.0478,  0.0713, -0.0987,  0.0386, -0.0161,  0.0888,  0.0139,\n",
       "         -0.1627, -0.0074],\n",
       "        [-0.1738,  0.1623,  0.1382, -0.1037,  0.1853,  0.1476,  0.0752, -0.1525,\n",
       "         -0.0598, -0.1010],\n",
       "        [ 0.0496,  0.2936, -0.0792, -0.3501,  0.1942, -0.2387,  0.3533, -0.2103,\n",
       "         -0.0929, -0.1246],\n",
       "        [ 0.0555, -0.0137,  0.2880, -0.3597,  0.1572,  0.0500,  0.2893, -0.0997,\n",
       "          0.0016, -0.0916],\n",
       "        [ 0.1730,  0.3185, -0.0694, -0.0009,  0.1943,  0.0525,  0.1658,  0.0319,\n",
       "          0.0504, -0.0589],\n",
       "        [ 0.2190,  0.2284,  0.0114,  0.1231,  0.0850, -0.1823,  0.0464,  0.0338,\n",
       "         -0.2613, -0.0155],\n",
       "        [ 0.0251, -0.0213,  0.0505, -0.0777,  0.0509,  0.0881, -0.0371,  0.0609,\n",
       "         -0.0132, -0.0442],\n",
       "        [ 0.3184,  0.0444, -0.0546,  0.0643,  0.0695,  0.0768,  0.1390, -0.1619,\n",
       "          0.1274, -0.2762],\n",
       "        [ 0.0278,  0.0139,  0.0014,  0.1706,  0.4914,  0.1173, -0.0086, -0.3395,\n",
       "         -0.0491, -0.0981]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X.view(-1, 28*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [600/600], Loss: 2.3230\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.7352\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.4244\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.1426\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0584\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # <=> x.grad += dloss/dx for all parameters x\n",
    "    \n",
    "    optimizer.step()\n",
    "    print('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "           % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 75 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
